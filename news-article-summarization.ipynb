{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-DailyMail News Text Summarization\n",
    "\n",
    "T5 Model is used to perform Seq2Seq task of text summarization of news articles.\n",
    "\n",
    "<img src=\"images/31.png\">\n",
    "\n",
    "Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., & Liu, P. J. (2019). Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer. arXiv. https://doi.org/10.48550/ARXIV.1910.10683"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Text Summarization code from the Hugging Face course is used for reference.\n",
    "https://huggingface.co/course/chapter7/5?fw=pt#finetuning-mt5-with-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Hugging Face libraries\n",
    "!pip install datasets transformers[sentencepiece]\n",
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-04-11T23:00:35.043769Z",
     "iopub.status.busy": "2022-04-11T23:00:35.043496Z",
     "iopub.status.idle": "2022-04-11T23:00:35.049336Z",
     "shell.execute_reply": "2022-04-11T23:00:35.048613Z",
     "shell.execute_reply.started": "2022-04-11T23:00:35.043740Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_metric\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import Seq2SeqTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T23:01:26.399889Z",
     "iopub.status.busy": "2022-04-11T23:01:26.399272Z",
     "iopub.status.idle": "2022-04-11T23:01:49.305123Z",
     "shell.execute_reply": "2022-04-11T23:01:49.304298Z",
     "shell.execute_reply.started": "2022-04-11T23:01:26.399851Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the Kaggle dataset https://www.kaggle.com/datasets/gowrishankarp/newspaper-text-summarization-cnn-dailymail\n",
    "dataset = load_dataset('csv', data_files={'train': '../input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/train.csv', \n",
    "                                          'validation': '../input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/validation.csv' , \n",
    "                                          'test': '../input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/test.csv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T23:01:49.314836Z",
     "iopub.status.busy": "2022-04-11T23:01:49.314362Z",
     "iopub.status.idle": "2022-04-11T23:02:12.389911Z",
     "shell.execute_reply": "2022-04-11T23:02:12.389151Z",
     "shell.execute_reply.started": "2022-04-11T23:01:49.314800Z"
    }
   },
   "outputs": [],
   "source": [
    "# T5 model is used\n",
    "model_checkpoint = \"google/t5-v1_1-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T00:35:46.404118Z",
     "iopub.status.busy": "2022-04-12T00:35:46.403425Z",
     "iopub.status.idle": "2022-04-12T00:35:46.409468Z",
     "shell.execute_reply": "2022-04-12T00:35:46.408791Z",
     "shell.execute_reply.started": "2022-04-12T00:35:46.404077Z"
    }
   },
   "outputs": [],
   "source": [
    "# Maximum Input Length for the news article and maximum output length for the summarization. \n",
    "max_input_length = 512\n",
    "max_target_length = 75\n",
    "\n",
    "# Preprocessing function to process the dataset.\n",
    "def preprocess_function(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"article\"], max_length=max_input_length, truncation=True,padding=True\n",
    "    )\n",
    "    # Set up the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            examples[\"highlights\"], max_length=max_target_length, truncation=True,padding=True\n",
    "        )\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T23:02:12.400720Z",
     "iopub.status.busy": "2022-04-11T23:02:12.400119Z",
     "iopub.status.idle": "2022-04-11T23:17:41.977453Z",
     "shell.execute_reply": "2022-04-11T23:17:41.976731Z",
     "shell.execute_reply.started": "2022-04-11T23:02:12.400680Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use map to apply the preprocessing function on the dataset\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROUGE Score\n",
    "\n",
    "<img src=\"images/32.png\">\n",
    "\n",
    "ROUGE Score computes precision and recall based on the similarity between the model's summarization output and the reference statement(label).\n",
    "\n",
    "\n",
    "<img src=\"images/33.png\">\n",
    "\n",
    "The precision and recall is combined using F1-score metric to get ROUGE F1.\n",
    "\n",
    "https://towardsdatascience.com/the-ultimate-performance-metric-in-nlp-111df6c64460"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T23:20:55.493749Z",
     "iopub.status.busy": "2022-04-11T23:20:55.493441Z",
     "iopub.status.idle": "2022-04-11T23:20:58.331866Z",
     "shell.execute_reply": "2022-04-11T23:20:58.331105Z",
     "shell.execute_reply.started": "2022-04-11T23:20:55.493714Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import rouge score metric\n",
    "rouge_score = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T23:20:58.333837Z",
     "iopub.status.busy": "2022-04-11T23:20:58.333587Z",
     "iopub.status.idle": "2022-04-11T23:21:22.427835Z",
     "shell.execute_reply": "2022-04-11T23:21:22.427022Z",
     "shell.execute_reply.started": "2022-04-11T23:20:58.333802Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load T5 Model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T01:06:17.288130Z",
     "iopub.status.busy": "2022-04-12T01:06:17.287864Z",
     "iopub.status.idle": "2022-04-12T01:06:17.299566Z",
     "shell.execute_reply": "2022-04-12T01:06:17.298697Z",
     "shell.execute_reply.started": "2022-04-12T01:06:17.288095Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "num_train_epochs = 1\n",
    "\n",
    "# Show the training loss with every epoch\n",
    "logging_steps = len(tokenized_dataset[\"train\"]) // batch_size\n",
    "\n",
    "# Load the Seq2Seq model training arguments. \n",
    "# The model is called Seq2Seq because the input data is a sequence of text and\n",
    "# the output data is also a sequence of text.\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"news summarizer\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5.6e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    predict_with_generate=True,\n",
    "    logging_steps=logging_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T01:06:19.842105Z",
     "iopub.status.busy": "2022-04-12T01:06:19.841523Z",
     "iopub.status.idle": "2022-04-12T01:06:19.849975Z",
     "shell.execute_reply": "2022-04-12T01:06:19.849012Z",
     "shell.execute_reply.started": "2022-04-12T01:06:19.842068Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function for Computing ROUGE score metric.\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    # Decode generated summaries into text\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    # Decode reference summaries into text\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    # ROUGE expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    # Compute ROUGE scores\n",
    "    result = rouge_score.compute(\n",
    "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
    "    )\n",
    "    # Extract the median scores\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T01:06:23.005038Z",
     "iopub.status.busy": "2022-04-12T01:06:23.004421Z",
     "iopub.status.idle": "2022-04-12T01:06:23.009045Z",
     "shell.execute_reply": "2022-04-12T01:06:23.008332Z",
     "shell.execute_reply.started": "2022-04-12T01:06:23.004996Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data collator forms batches of input data.\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T01:06:24.566972Z",
     "iopub.status.busy": "2022-04-12T01:06:24.566245Z",
     "iopub.status.idle": "2022-04-12T01:06:24.580310Z",
     "shell.execute_reply": "2022-04-12T01:06:24.579504Z",
     "shell.execute_reply.started": "2022-04-12T01:06:24.566930Z"
    }
   },
   "outputs": [],
   "source": [
    "# Seq2Seq to train the model.\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T01:06:26.593794Z",
     "iopub.status.busy": "2022-04-12T01:06:26.593497Z",
     "iopub.status.idle": "2022-04-12T01:06:26.598395Z",
     "shell.execute_reply": "2022-04-12T01:06:26.597682Z",
     "shell.execute_reply.started": "2022-04-12T01:06:26.593763Z"
    }
   },
   "outputs": [],
   "source": [
    "# WANDB is disabled.\n",
    "%env WANDB_DISABLED=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T01:06:37.771478Z",
     "iopub.status.busy": "2022-04-12T01:06:37.771222Z",
     "iopub.status.idle": "2022-04-12T01:15:10.522026Z",
     "shell.execute_reply": "2022-04-12T01:15:10.521030Z",
     "shell.execute_reply.started": "2022-04-12T01:06:37.771448Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train the model.\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T01:15:15.360636Z",
     "iopub.status.busy": "2022-04-12T01:15:15.360358Z",
     "iopub.status.idle": "2022-04-12T01:23:58.874341Z",
     "shell.execute_reply": "2022-04-12T01:23:58.873391Z",
     "shell.execute_reply.started": "2022-04-12T01:15:15.360605Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use the trained model for evaluation.\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
